{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart Disease Prediction",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "qur81QSsLYku",
        "outputId": "291ac24f-4c82-41b2-cab4-5151edffe515"
      },
      "source": [
        "import pandas as pd\n",
        " \n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category = FutureWarning)\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category = FutureWarning)\n",
        " \n",
        " \n",
        "df = pd.read_csv('cleveland.csv', header = None)\n",
        " \n",
        "df.columns = ['age', 'sex', 'cp', 'trestbps', 'chol',\n",
        "              'fbs', 'restecg', 'thalach', 'exang', \n",
        "              'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        " \n",
        "### 1 = male, 0 = female\n",
        "df.isnull().sum()\n",
        " \n",
        "df['target'] = df.target.map({0: 0, 1: 1, 2: 1, 3: 1, 4: 1})\n",
        "df['sex'] = df.sex.map({0: 'female', 1: 'male'})\n",
        "df['thal'] = df.thal.fillna(df.thal.mean())\n",
        "df['ca'] = df.ca.fillna(df.ca.mean())\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        " \n",
        "# distribution of target vs age \n",
        "sns.set_context(\"paper\", font_scale = 2, rc = {\"font.size\": 20,\"axes.titlesize\": 25,\"axes.labelsize\": 20}) \n",
        "sns.catplot(kind = 'count', data = df, x = 'age', hue = 'target', order = df['age'].sort_values().unique())\n",
        "plt.title('Variation of Age for each target class')\n",
        "plt.show()\n",
        " \n",
        " \n",
        "# barplot of age vs sex with hue = target\n",
        "sns.catplot(kind = 'bar', data = df, y = 'age', x = 'sex', hue = 'target')\n",
        "plt.title('Distribution of age vs sex with the target class')\n",
        "plt.show()\n",
        " \n",
        "df['sex'] = df.sex.map({'female': 0, 'male': 1})\n",
        " \n",
        " \n",
        "################################## data preprocessing\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        " \n",
        "from sklearn.preprocessing import StandardScaler as ss\n",
        "sc = ss()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        " \n",
        "#########################################   SVM   #############################################################\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf')\n",
        "classifier.fit(X_train, y_train)\n",
        " \n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_test = confusion_matrix(y_pred, y_test)\n",
        " \n",
        "y_pred_train = classifier.predict(X_train)\n",
        "cm_train = confusion_matrix(y_pred_train, y_train)\n",
        " \n",
        "print()\n",
        "print('Accuracy for training set for svm = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
        "print('Accuracy for test set for svm = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))\n",
        " \n",
        " \n",
        "#########################################   Naive Bayes  #############################################################\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        " \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        " \n",
        " \n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_test = confusion_matrix(y_pred, y_test)\n",
        " \n",
        "y_pred_train = classifier.predict(X_train)\n",
        "cm_train = confusion_matrix(y_pred_train, y_train)\n",
        " \n",
        "print()\n",
        "print('Accuracy for training set for Naive Bayes = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
        "print('Accuracy for test set for Naive Bayes = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))\n",
        " \n",
        " \n",
        "#########################################   Logistic Regression  #############################################################\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        " \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        " \n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_test = confusion_matrix(y_pred, y_test)\n",
        " \n",
        "y_pred_train = classifier.predict(X_train)\n",
        "cm_train = confusion_matrix(y_pred_train, y_train)\n",
        " \n",
        "print()\n",
        "print('Accuracy for training set for Logistic Regression = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
        "print('Accuracy for test set for Logistic Regression = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))\n",
        " \n",
        "#########################################   Decision Tree  #############################################################\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        " \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        " \n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_test = confusion_matrix(y_pred, y_test)\n",
        " \n",
        "y_pred_train = classifier.predict(X_train)\n",
        "cm_train = confusion_matrix(y_pred_train, y_train)\n",
        " \n",
        "print()\n",
        "print('Accuracy for training set for Decision Tree = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
        "print('Accuracy for test set for Decision Tree = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))\n",
        " \n",
        " \n",
        "#########################################  Random Forest  #############################################################\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        " \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10)\n",
        "classifier.fit(X_train, y_train)\n",
        " \n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_test = confusion_matrix(y_pred, y_test)\n",
        " \n",
        "y_pred_train = classifier.predict(X_train)\n",
        "cm_train = confusion_matrix(y_pred_train, y_train)\n",
        " \n",
        "print()\n",
        "print('Accuracy for training set for Random Forest = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
        "print('Accuracy for test set for Random Forest = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))\n",
        " \n",
        "###############################################################################\n",
        "# applying lightGBM\n",
        "import lightgbm as lgb\n",
        " \n",
        "d_train = lgb.Dataset(X_train, label = y_train)\n",
        "params = {}\n",
        " \n",
        "clf = lgb.train(params, d_train, 100)\n",
        "#Prediction\n",
        "y_pred = clf.predict(X_test)\n",
        "#convert into binary values\n",
        "for i in range(0, len(y_pred)):\n",
        "    if y_pred[i]>= 0.5:       # setting threshold to .5\n",
        "       y_pred[i]=1\n",
        "    else:  \n",
        "       y_pred[i]=0\n",
        "       \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_test = confusion_matrix(y_pred, y_test)\n",
        " \n",
        "y_pred_train = clf.predict(X_train)\n",
        " \n",
        "for i in range(0, len(y_pred_train)):\n",
        "    if y_pred_train[i]>= 0.5:       # setting threshold to .5\n",
        "       y_pred_train[i]=1\n",
        "    else:  \n",
        "       y_pred_train[i]=0\n",
        "       \n",
        "cm_train = confusion_matrix(y_pred_train, y_train)\n",
        "print()\n",
        "print('Accuracy for training set for LightGBM = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
        "print('Accuracy for test set for LightGBM = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))\n",
        " \n",
        " \n",
        "###############################################################################\n",
        "# applying XGBoost\n",
        " \n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.20, random_state = 0)\n",
        " \n",
        "from xgboost import XGBClassifier\n",
        "xg = XGBClassifier()\n",
        "xg.fit(X_train, y_train)\n",
        "y_pred = xg.predict(X_test)\n",
        " \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_test = confusion_matrix(y_pred, y_test)\n",
        " \n",
        "y_pred_train = xg.predict(X_train)\n",
        " \n",
        "for i in range(0, len(y_pred_train)):\n",
        "    if y_pred_train[i]>= 0.5:       # setting threshold to .5\n",
        "       y_pred_train[i]=1\n",
        "    else:  \n",
        "       y_pred_train[i]=0\n",
        "       \n",
        "cm_train = confusion_matrix(y_pred_train, y_train)\n",
        "print()\n",
        "print('Accuracy for training set for XGBoost = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))\n",
        "print('Accuracy for test set for XGBoost = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dcc7e7bb5c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cleveland.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m df.columns = ['age', 'sex', 'cp', 'trestbps', 'chol',\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cleveland.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmtGpT48XbjW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfvVMgQ4XZoq"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T0Neq-SwPHe"
      },
      "source": [
        ""
      ]
    }
  ]
}